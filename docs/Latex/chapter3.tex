% !TEX root = master.tex
\chapter{Anwendung} \label{chapter:3}
%Grafische Darstellung des Lernprozesses, zentraler Ergebnisse und Beispiele der Agenten.

Die in \ref{chapter:2} beschriebenen Methoden erwiesen sich bei ihrer Anwendung auf das ``Soccer-Tows'' Problem als unterschiedliche erfolgreich.


\iffalse %tempor채r auskommentiert

%Single Agent Methods
\ref{fig:bild} zeigt ein Vergleich der verschiedenen Methoden mit Werten f체r die angepassten Belohnungsstruktur links und original Belohung (Tor oder Gegentor) f체r ein Spiel rechts.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{img/soccer_twos.png}
	\caption{Caption BOXPLOTS}
	\label{fig:bild}
\end{figure}

Es ist zu erkennen, dass die Off-Policy Methoden \ac{XY} und \ac{XY} die schlechtesten Ergenisse liefern. \ac{XY} zeigt einen mit ... einen mitterleren Erfolg. Die besten Ergenisse erziehlt der \ac{PPO} Algorithmus, welcher ... .
Im Vergleich zu der entwickleten Baseline-Methode ist es ersichtlich das .... .


\ref{fig:bild2} stellt .... dar. 

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{img/soccer_twos.png}
	\caption{Caption ANDERE GRAFIK}
	\label{fig:bild2}
\end{figure}

Auch diese Darstellung unterstricht die zuvor beschriebenen Erkennisse. (... was hier noch neu rausgelsen wird)


%MARL

Die Anweung des ``competetiv-self play'' Verfahrens f체r das Mulit-Agent-Szenario ....

\fi