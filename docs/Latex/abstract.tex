% !TEX root =  master.tex
\chapter*{Abstract}

Das Training von \ac{RL} Agents in simulierten Spielumgebungen ist eine verbreitete und geeignete Herangehensweise, um \ac{RL}-Verfahren zu erlernen und zu vergleichen. Oftmals finden diese Verfahren Anwendung in sehr einfachen Umgebungen mit einem Agenten und wenigen Beobachtungen. Besonders interessant und eine reizende Herausforderung ist es jedoch, wenn die Umgebung einen Realitätsbezug hat und eine erweiterte Komplexität aufweist.

Im Rahmen dieser Gruppenarbeit wurden daher verschiedene \ac{RL}-Verfahren für die ``Soccer-Twos''-Umgebung, welche ein Fußballspiel zwischen mehreren Agents simuliert, implementiert und ausgewertet. Zum einen wurden Single-Agent-Methoden betrachtet, bei denen ein Agent allein ein Tor schießen soll. Zum anderen wurde das deutlich komplexere \ac{MARL} Problem angegangen, und eine erstes Trainingsverfahren in Form von ``competitive self-play'' entwickelt.

Die Evaluierung und der Vergleich mit einer einfachen Baseline-Methode ergeben, dass die Ergebnisse noch ausbaufähig sind. Jedoch zeigen die ersten Ansätze wie \ac{PPO} vielversprechende Erfolge, und auch die Betrachtung der Multi-Agent-Umgebung erweist sich als wertvoll.